{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ha_ha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ha_ha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip function\n",
    "- \\n is absorbed when printing only that text\n",
    "- \\n is not absorbed when printing all the texts in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How to Bake Breads Without Baking Recipes\\n', 'Smith Pies: Best Pies in London\\n', 'Numerical Recipes: The Art of Scientific Computing\\n', 'Breads, Pastries, Pies, and Cakes: Quantity Baking Recipes\\n', 'Pastry: A Book of Best French Pastry Recipes'] \n",
      "\n",
      "['How to Bake Breads Without Baking Recipes', 'Smith Pies: Best Pies in London', 'Numerical Recipes: The Art of Scientific Computing', 'Breads, Pastries, Pies, and Cakes: Quantity Baking Recipes', 'Pastry: A Book of Best French Pastry Recipes'] \n",
      "\n",
      " to Bake Breads Without Baking Recipes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"01.Vector_Space_Retrieval\\\\bread.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "print(content, '\\n')\n",
    "print([x.strip() for x in content], '\\n')\n",
    "print(content[0].strip('How'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords removal\n",
    "- remove special characters !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "- \"\".join tells us not to add any spacings between the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smith Pies Best Pies in London\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\".join([ch for ch in content[1] if ch not in string.punctuation])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize vs Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smith Pies: Best Pies in London\n",
      "\n",
      "['Smith', 'Pies', ':', 'Best', 'Pies', 'in', 'London']\n",
      "['Smith', 'Pies:', 'Best', 'Pies', 'in', 'London']\n"
     ]
    }
   ],
   "source": [
    "print(content[1])\n",
    "print(nltk.word_tokenize(content[1]))\n",
    "print(content[1].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[('Recipes', 3), ('of', 2)]\n",
      "3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-03f4cd1c5707>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "# Convert the sentences into a list of list-of-words\n",
    "sentences = [sentence.split() for sentence in content]\n",
    "# Flatten the list\n",
    "words = [word for sentence in sentences for word in sentence]\n",
    "\n",
    "# Counter\n",
    "counts = Counter(words)\n",
    "\n",
    "# Print the count for the word recipe\n",
    "print(counts['Recipes'])\n",
    "\n",
    "# Print the 2 most common words\n",
    "print(counts.most_common(2))\n",
    "\n",
    "# Print the count of the most common word\n",
    "print(counts.most_common(1)[0][1])\n",
    "\n",
    "# !!!!!! Cannot flatten lists \n",
    "# sentences = [sentence.split() for sentence in content]\n",
    "# print(sentences.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 7}\n"
     ]
    }
   ],
   "source": [
    "d_dict = {}\n",
    "d_dict['a'] = 1\n",
    "\n",
    "d_set = {7,2,3}\n",
    "print(d_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple is a fruit', 'he is a king']\n",
      "['algae, such as gelidium']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "a = \"apple is a fruit. he is a king\"\n",
    "b = \"red algae, such as gelidium\"\n",
    "\n",
    "# set pattern\n",
    "regexp_a = re.compile(\"[a-z]+ is a [a-z]+\")\n",
    "regexp_b = re.compile(\"[a-z]+, such as [a-z]+\")\n",
    "\n",
    "#Find all matches with the given regular expression\n",
    "matches_a = re.findall(regexp_a, a)\n",
    "matches_b = re.findall(regexp_b, b)\n",
    "print(matches_a)\n",
    "print(matches_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and joining text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'orange', 'man']\n",
      "apple orange man\n"
     ]
    }
   ],
   "source": [
    "a = \"apple orange man\"\n",
    "a = a.split(' ')\n",
    "print(a)\n",
    "print(\" \".join(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substituting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple cake cake man\n"
     ]
    }
   ],
   "source": [
    "a = \"apple orange orange man\"\n",
    "print(re.sub(pattern=\"orange\",repl=\"cake\",string=a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sorting the elements of a dictionary element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('company', 0.0747098410221),\n",
       " ('brand', 0.0915626602388),\n",
       " ('crop', 0.147812587177),\n",
       " ('apple', 0.41334243636)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "d['apple'] = {}\n",
    "d['apple']['apple'] = 0.41334243636\n",
    "d['apple']['brand'] = 0.0915626602388\n",
    "d['apple']['company'] = 0.0747098410221\n",
    "d['apple']['crop'] = 0.147812587177\n",
    "\n",
    "sorted(d['apple'].items(), key= lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sorting the elements of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dave', 'C'), ('jane', 'A'), ('john', 'F')]\n"
     ]
    }
   ],
   "source": [
    "students = ['dave', 'john', 'jane']\n",
    "newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}\n",
    "print(sorted(newgrades.items(), key= lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looping through a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jane A\n",
      "john F\n",
      "dave C\n"
     ]
    }
   ],
   "source": [
    "newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}\n",
    "for key,value in newgrades.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split array and print elements that are equal to value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([1,2,1,2,1,2,1,2,1])\n",
    "l = temp[:4]\n",
    "r = temp[4:]\n",
    "print(l[l == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 5 4 3 2 1]\n",
      "[7 6 5 4 3 2]\n",
      "[7 5 3 1]\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([1,2,3,4,5,6,7])\n",
    "print(temp[::-1])\n",
    "print(temp[-1:0:-1])\n",
    "print(temp[::-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[[1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [3 3 3 3 3]\n",
      " [4 4 4 4 4]\n",
      " [5 5 5 5 5]]\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([3,1,4,5,2])\n",
    "tamp = np.array([[3,3,3,3,3],[1,1,1,1,1],[4,4,4,4,4],[5,5,5,5,5],[2,2,2,2,2]])\n",
    "ind = np.argsort(temp)\n",
    "print(temp[ind])\n",
    "print(tamp[ind,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]])\n",
    "ind = np.where((temp == 3) | (temp == 13))\n",
    "\n",
    "print(ind[0]) # 1st element\n",
    "print(ind[1]) # 2nd element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12  0 14 15]]\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]])\n",
    "temp[temp == 13] = 0\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# initialize list\n",
    "l = [0]*3\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9, 'c'], [0.7, 'b'], [0.5, 'a']]\n"
     ]
    }
   ],
   "source": [
    "scores = [[0.5,\"a\"], [0.7,\"b\"], [0.9,\"c\"]]\n",
    "scores.sort(key=lambda x: -x[0])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68 96 99 50]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.randint(low=1, high=100, size=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746318461970762\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,0,0])\n",
    "b = np.array([4,5,6,0,0])\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    numerator = a.dot(b)\n",
    "    denominator = np.linalg.norm(a,2) * np.linalg.norm(b,2)\n",
    "    \n",
    "    return numerator/denominator\n",
    "print(cosine_similarity(a,b))\n",
    "\n",
    "c = np.array([1,2,3])\n",
    "d = np.array([3,6,9])\n",
    "print(cosine_similarity(c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def H(a,b):\n",
    "    return -(a/(a+b))*np.log2(a/(a+b)) -(b/(a+b))*np.log2(b/(a+b))\n",
    "\n",
    "H(3,6)\n",
    "#print(0.75*H(0.65/(0.65+0.1), 0.1/(0.65+0.1)) + 0.25*H(0.1/(0.15+0.1), 0.15/(0.15+0.1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DIS2018)",
   "language": "python",
   "name": "dis2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
